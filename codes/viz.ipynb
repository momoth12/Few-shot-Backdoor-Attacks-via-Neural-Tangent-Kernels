{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_cifar_dataset, PoisonedDataset, LabelPoisoner,PixelPoisoner\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "train_dataset = load_cifar_dataset(train=True)\n",
    "test_dataset = load_cifar_dataset(train=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract images and labels\n",
    "train_images = np.array([sample[0] for sample in train_dataset])\n",
    "train_labels = np.array([sample[1] for sample in train_dataset])\n",
    "test_images = np.array([sample[0] for sample in test_dataset])\n",
    "test_labels = np.array([sample[1] for sample in test_dataset])\n",
    "\n",
    "# Stack images and labels separately\n",
    "all_images = np.vstack([train_images, test_images])\n",
    "all_labels = np.hstack([train_labels, test_labels])\n",
    "\n",
    "# Save to .npz format for better organization\n",
    "np.savez('output/X-94-1xs-perm', images=all_images, labels=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a poisoner for specific labels if needed\n",
    "pix=PixelPoisoner()\n",
    "poisoner = LabelPoisoner(pix, target_label=1)\n",
    "poisoned_train_dataset = PoisonedDataset(train_dataset, poisoner, label=0, eps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf2jax\\_src\\tf2jax.py:305: The name tf.NodeDef is deprecated. Please use tf.compat.v1.NodeDef instead.\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from ntk_cifar import kernel_fit, x_train_c, y_train_c, x_test_c, y_test_c\n",
    "from models import WideResnet,SimpleCNN,ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_c, y_train_c = x_train_c[:90], y_train_c[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m _, _, kernel_fn \u001b[38;5;241m=\u001b[39m ConvNeXt( num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fit the kernel to the training data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model, g_dd, predictor \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_c\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mouha\\Desktop\\ntk-backdoor\\ntk_cifar.py:131\u001b[0m, in \u001b[0;36mkernel_fit\u001b[1;34m(kernel_fn, x_tr, y_tr, lam, batch_size, device_count, store_on_device)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel_fit\u001b[39m(\n\u001b[0;32m    122\u001b[0m     kernel_fn,\n\u001b[0;32m    123\u001b[0m     x_tr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     store_on_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    129\u001b[0m ):\n\u001b[0;32m    130\u001b[0m     classes \u001b[38;5;241m=\u001b[39m y_tr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 131\u001b[0m     g_dd \u001b[38;5;241m=\u001b[39m \u001b[43mnt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_on_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mntk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mpredict\u001b[38;5;241m.\u001b[39mgradient_descent_mse(\n\u001b[0;32m    135\u001b[0m         g_dd, y_tr[:, np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m classes, diag_reg\u001b[38;5;241m=\u001b[39mlam\n\u001b[0;32m    136\u001b[0m     )\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(\n\u001b[0;32m    139\u001b[0m         x_te,\n\u001b[0;32m    140\u001b[0m         t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m         store_on_device\u001b[38;5;241m=\u001b[39mstore_on_device,\n\u001b[0;32m    144\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\utils\\utils.py:190\u001b[0m, in \u001b[0;36mwraps.<locals>.wrapper.<locals>.h\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mh\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:494\u001b[0m, in \u001b[0;36m_serial.<locals>.serial_fn\u001b[1;34m(x1_or_kernel, x2, *args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(kernel_fn)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserial_fn\u001b[39m(x1_or_kernel: Union[NTTree[jnp\u001b[38;5;241m.\u001b[39mndarray], NTTree[Kernel]],\n\u001b[0;32m    490\u001b[0m               x2: Optional[NTTree[Optional[jnp\u001b[38;5;241m.\u001b[39mndarray]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m               \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    492\u001b[0m               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NTTree[Kernel]:\n\u001b[0;32m    493\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_nt_tree_of(x1_or_kernel, (np\u001b[38;5;241m.\u001b[39mndarray, jnp\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serial_fn_x1(x1_or_kernel, x2, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    495\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_nt_tree_of(x1_or_kernel, Kernel):\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:421\u001b[0m, in \u001b[0;36m_serial.<locals>.serial_fn_x1\u001b[1;34m(x1, x2, *args, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m   kwargs_merge \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    416\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_other,\n\u001b[0;32m    417\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m((k, (kwargs1[k], kwargs2[k])) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs1)\n\u001b[0;32m    418\u001b[0m   }\n\u001b[0;32m    419\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (x1, kwargs1), kernel_fn(x1, x2, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_merge)\n\u001b[1;32m--> 421\u001b[0m _, kernel \u001b[38;5;241m=\u001b[39m \u001b[43m_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_np1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flatten(kernel, x2_is_none)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:161\u001b[0m, in \u001b[0;36m_scan\u001b[1;34m(f, init, xs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flat_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_xs):\n\u001b[0;32m    160\u001b[0m   x \u001b[38;5;241m=\u001b[39m tree_unflatten(tree_def, flat_x)\n\u001b[1;32m--> 161\u001b[0m   carry, y \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m   ys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [y]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m carry, tree_map(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39my: jnp\u001b[38;5;241m.\u001b[39mstack(y), \u001b[38;5;241m*\u001b[39mys)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:410\u001b[0m, in \u001b[0;36m_serial.<locals>.serial_fn_x1.<locals>.row_fn\u001b[1;34m(_, x1)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrow_fn\u001b[39m(_, x1):\n\u001b[1;32m--> 410\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _, \u001b[43m_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_np2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:161\u001b[0m, in \u001b[0;36m_scan\u001b[1;34m(f, init, xs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flat_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_xs):\n\u001b[0;32m    160\u001b[0m   x \u001b[38;5;241m=\u001b[39m tree_unflatten(tree_def, flat_x)\n\u001b[1;32m--> 161\u001b[0m   carry, y \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m   ys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [y]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m carry, tree_map(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39my: jnp\u001b[38;5;241m.\u001b[39mstack(y), \u001b[38;5;241m*\u001b[39mys)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:419\u001b[0m, in \u001b[0;36m_serial.<locals>.serial_fn_x1.<locals>.col_fn\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m    414\u001b[0m x2, kwargs2 \u001b[38;5;241m=\u001b[39m x2\n\u001b[0;32m    415\u001b[0m kwargs_merge \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_other,\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m((k, (kwargs1[k], kwargs2[k])) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs1)\n\u001b[0;32m    418\u001b[0m }\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x1, kwargs1), kernel_fn(x1, x2, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_merge)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\utils\\utils.py:190\u001b[0m, in \u001b[0;36mwraps.<locals>.wrapper.<locals>.h\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mh\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neural_tangents\\_src\\batching.py:780\u001b[0m, in \u001b[0;36m_get_jit_or_pmap_broadcast.<locals>.jit_or_pmap_broadcast.<locals>.f_pmapped\u001b[1;34m(x_or_kernel, *args, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# Broadcast `jnp.ndarray` arguments and apply the new function to them.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m args_np \u001b[38;5;241m=\u001b[39m tree_map(broadcast, args_np)\n\u001b[1;32m--> 780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _f(x_or_kernel, \u001b[38;5;241m*\u001b[39margs_np, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_np)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the kernel function\n",
    "#_, _, kernel_fn = WideResnet(block_size=4, k=5, num_classes=1)\n",
    "_, _, kernel_fn = ConvNeXt( num_classes=1)\n",
    "\n",
    "# Fit the kernel to the training data\n",
    "model, g_dd, predictor = kernel_fit(kernel_fn, x_train_c, y_train_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'slice(0, 1000, None) is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28miter\u001b[39m, lr, tx, params, opt_state\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize JAX key and model parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mouha\\Desktop\\ntk-backdoor\\train_fast.py:61\u001b[0m\n\u001b[0;32m     59\u001b[0m n, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m200\u001b[39m \u001b[38;5;66;03m#mouhamadou\u001b[39;00m\n\u001b[0;32m     60\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_file)\n\u001b[1;32m---> 61\u001b[0m x_train_c, x_train_p, x_train_pp, x_test_c, x_test_p, x_test_pp \u001b[38;5;241m=\u001b[39m \u001b[43mvsplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m Xd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([x_train_c, x_train_pp])\n\u001b[0;32m     65\u001b[0m Yd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(x_train_c), \u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(x_train_pp), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32mc:\\Users\\mouha\\Desktop\\ntk-backdoor\\jax_utils.py:325\u001b[0m, in \u001b[0;36mvsplit\u001b[1;34m(a, check, *block_sizes)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bs, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    324\u001b[0m         bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(bs)\n\u001b[1;32m--> 325\u001b[0m     blocks\u001b[38;5;241m.\u001b[39mappend(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    326\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bs\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check:\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:263\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'slice(0, 1000, None) is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "from train_fast import iter, lr, tx, params, opt_state\n",
    "import jax\n",
    "\n",
    "# Initialize JAX key and model parameters\n",
    "key = jax.random.PRNGKey(0)\n",
    "num_epochs = 10\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    (params, opt_state, key), metrics = iter(epoch, params, opt_state, key)\n",
    "    avg_loss, avg_acc, avg_tloss, avg_tacc, avg_ploss, avg_pacc, p_pred = metrics\n",
    "    print(f\"Epoch {epoch}: Loss={avg_loss:.4f}, Accuracy={avg_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import compute_all_reps, clf_eval\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_acc, test_loss = clf_eval(model, test_dataset)\n",
    "print(f\"Test Accuracy: {test_acc}, Test Loss: {test_loss}\")\n",
    "\n",
    "# Extract representations from specific layers\n",
    "layer_reps = compute_all_reps(model, train_dataset, layers=[0, 2, 4])\n",
    "print(\"Layer representations extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"ntk-backdoor\", entity=\"your_entity\")\n",
    "wandb.log({\"train_loss\": avg_loss, \"train_acc\": avg_acc})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
